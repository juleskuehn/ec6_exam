{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Fellowship program exam\n",
    "\n",
    "**Machine Learning - Assignment 2: Natural disasters dataset**\n",
    "\n",
    "By: Jules Kuehn\n",
    "\n",
    "Due: 2020-12-03, 6pm Eastern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Feature generation and traditional ML model\n",
    "\n",
    "Not implemented, but would be nice:\n",
    "* Common functions moved to python module, to be imported into multiple notebooks.\n",
    "* (Some code is duplicated here from the previous notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import re\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "Use Pandas to import the CSV to a Dataframe. For a larger dataset, I would use Spark for pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "disaster_tweets = train_df[train_df['target'] == 1]['text'].tolist()\n",
    "non_disaster_tweets = train_df[train_df['target'] == 0]['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF feature extraction\n",
    "\n",
    "We will start with the CountVectorizer from the previous notebook, then apply TF-IDF processing.\n",
    "\n",
    "Note that custom pre-processing was found to be unnecessary, so our pipeline begins with the CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer(\n",
    "    non_disaster_tweets,\n",
    "    disaster_tweets,\n",
    "    initial_vocab='all',\n",
    "    remove_n_common_words=5,\n",
    "    min_df=5,\n",
    "    max_features=None,\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 1),\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a CountVectorizer for use in a bag-of-words model.\n",
    "    Takes a list of non-disaster tweets and a list of disaster tweets.\n",
    "    Optionally removes some common or uncommon words.\n",
    "    Returns a CountVectorizer with the limited vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    if initial_vocab == 'disaster':\n",
    "        initial_vocab_tweets = disaster_tweets\n",
    "    else:\n",
    "        initial_vocab_tweets = non_disaster_tweets + disaster_tweets\n",
    "\n",
    "    # Get vocabulary from tweets (optionally removing uncommon words)\n",
    "    transformer = CountVectorizer(\n",
    "        strip_accents=strip_accents,\n",
    "        lowercase=lowercase,\n",
    "        min_df=min_df,\n",
    "        max_features=max_features,\n",
    "        ngram_range=ngram_range,\n",
    "    ).fit(initial_vocab_tweets)\n",
    "\n",
    "    if remove_n_common_words > 0:\n",
    "        final_vocabulary = transformer.vocabulary_.copy()\n",
    "        # Get the most common words in the non-disaster tweets\n",
    "        transformer = CountVectorizer(\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            min_df=min_df,\n",
    "            ngram_range=ngram_range,\n",
    "        ).fit(non_disaster_tweets)\n",
    "        bow = transformer.transform(list(non_disaster_tweets) + list(disaster_tweets))\n",
    "        word_freqs = dict(zip(\n",
    "            transformer.get_feature_names_out(),\n",
    "            np.asarray(bow.sum(axis=0))[0]\n",
    "        ))\n",
    "        common_words = sorted(\n",
    "            word_freqs.items(), key=lambda x: x[1], reverse=True\n",
    "        )[:remove_n_common_words]\n",
    "\n",
    "        # Remove most common non-disaster words from disaster tweets vocabulary\n",
    "        for word in common_words:\n",
    "            final_vocabulary.pop(word[0], None)\n",
    "\n",
    "        # Create the final vectorizer with the limited vocabulary\n",
    "        transformer = CountVectorizer(\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            vocabulary=final_vocabulary.keys(),\n",
    "            ngram_range=ngram_range,\n",
    "        ).fit(disaster_tweets)\n",
    "    \n",
    "    return transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and evaluation\n",
    "\n",
    "Note that I am not using the test data at this time. I am only using the training data while testing pre-processing hyperparameters.\n",
    "\n",
    "(We will use the test data in the last task of this exam, to compare all models.)\n",
    "\n",
    "This code is largely the same as in notebook 1_BoW, but with the TF-IDF transformer added and manual pre-processing steps removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preprocessing(\n",
    "    train_df,\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    initial_vocab='all',\n",
    "    remove_n_common_words=5,\n",
    "    min_df=5,\n",
    "    max_features=None,\n",
    "    verbose=False,\n",
    "    return_artifacts=False,\n",
    "    ngram_range=(1, 1),\n",
    "    use_idf=True,\n",
    "    norm='l2',\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=False,\n",
    "    clf=LogisticRegression(),\n",
    "    tfidf=True,\n",
    "):\n",
    "\n",
    "    non_disaster_tweets = train_df[train_df['target'] == 0]['text'].tolist()\n",
    "    disaster_tweets = train_df[train_df['target'] == 1]['text'].tolist()\n",
    "\n",
    "    # Create vectorizer with limited vocabulary\n",
    "    vectorizer = create_vectorizer(\n",
    "        non_disaster_tweets,\n",
    "        disaster_tweets,\n",
    "        initial_vocab=initial_vocab,\n",
    "        remove_n_common_words=remove_n_common_words,\n",
    "        min_df=min_df,\n",
    "        max_features=max_features,\n",
    "        strip_accents=strip_accents,\n",
    "        lowercase=lowercase,\n",
    "        ngram_range=ngram_range,\n",
    "    )\n",
    "    \n",
    "    # Fit TF-IDF transformer\n",
    "    all_tweets = train_df['text']\n",
    "    tfidf_transformer = TfidfTransformer(\n",
    "        use_idf=use_idf,\n",
    "        norm=norm,\n",
    "        smooth_idf=smooth_idf,\n",
    "        sublinear_tf=sublinear_tf,\n",
    "    ).fit(vectorizer.transform(all_tweets))\n",
    "\n",
    "    # Create a pipeline to vectorize and apply TF-IDF\n",
    "    # Classifier is passed as an argument for comparison\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('tfidf', tfidf_transformer if tfidf else None),\n",
    "        (\"clf\", clf),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    X_train = all_tweets\n",
    "    y_train = train_df['target']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    preds_val = pipeline.predict(X_val)\n",
    "\n",
    "    if verbose:\n",
    "        # Display results on validation set\n",
    "        print(classification_report(y_val, preds_val))\n",
    "        ConfusionMatrixDisplay.from_estimator(pipeline, X_val, y_val, cmap='Blues', normalize='true')\n",
    "    \n",
    "    if return_artifacts:\n",
    "        return pipeline, X_train, X_val, y_train, y_val\n",
    "\n",
    "    # Return f1 macro average score\n",
    "    return f1_score(y_val, preds_val, average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a model\n",
    "TF-IDF will not necessarily improve performance. Let's evaluate its effects with a variety of SkLearn models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result:\n",
      " ({'clf': SVC(max_iter=2000, random_state=42), 'tfidf': False, 'ngram_range': (1, 1)}, 0.789233228475146)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JKUEHN\\Anaconda3\\envs\\ec6_exam\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       874\n",
      "           1       0.82      0.68      0.74       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.789233228475146"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGwCAYAAABb6kfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3TUlEQVR4nO3deXhU5dnH8d9MYLKQhU0SCGETZZElGCQNVoE2EpeCaH1FRYmp8L4KUUpEBS1BQIkVxRRFYpGIWJdYVCqLKI2iICgFxIqFKJuEJYGIEBKabWbeP5DRkSAzmZmMM+f74TqXzZPnnHNPLy7uue/znHNMdrvdLgAAEBTM/g4AAAB4D4kdAIAgQmIHACCIkNgBAAgiJHYAAIIIiR0AgCBCYgcAIIg08XcAnrDZbDp48KCioqJkMpn8HQ4AwE12u10nTpxQu3btZDb7rtasqqpSTU2Nx8exWCwKCwvzQkS+E9CJ/eDBg0pISPB3GAAADxUXF6t9+/Y+OXZVVZXCo1pJdSc9PlZcXJz27Nnzi07uAZ3Yo6KiJEmWnukyhVj8HA3gG/vWPOHvEACfOVFerq6dExz/nvtCTU2NVHdSoT3TJU9yhbVGJf95UTU1NSR2XzndfjeFWEjsCFrR0dH+DgHwuUa5nNokzKNcYTcFxrK0gE7sAAC4zCTJky8QAbKUi8QOADAGk/nU5sn+ASAwogQAAC6hYgcAGIPJ5GErPjB68SR2AIAx0IoHAACBhoodAGAMtOIBAAgmHrbiA6TJHRhRAgAAl1CxAwCMgVY8AABBhFXxAAAg0FCxAwCMgVY8AABBxCCteBI7AMAYDFKxB8bXDwAA4BIqdgCAMdCKBwAgiJhMHiZ2WvEAAKCRUbEDAIzBbDq1ebJ/ACCxAwCMwSDX2AMjSgAA4BIqdgCAMRjkPnYSOwDAGGjFAwCAQEPFDgAwBlrxAAAEEYO04knsAABjMEjFHhhfPwAAgEuo2AEAxkArHgCAIEIrHgAABBoqdgCAQXjYig+QWpjEDgAwBlrxAAAg0FCxAwCMwWTycFV8YFTsJHYAgDEY5Ha3wIgSAIAANW/ePHXq1ElhYWFKTk7Wxo0bf3Z+bm6uunXrpvDwcCUkJGjixImqqqpy+XwkdgCAMZxePOfJ5qaCggJlZWVp2rRp2rJli/r27au0tDQdPny43vmvvPKKJk+erGnTpmn79u1auHChCgoK9OCDD7p8ThI7AMAYTrfiPdkklZeXO23V1dVnPeWcOXM0duxYZWRkqGfPnsrLy1NERITy8/Prnb9+/XpdeumluuWWW9SpUycNHTpUN9988zmr/B8jsQMAjMFLFXtCQoJiYmIcW05OTr2nq6mp0ebNm5WamuoYM5vNSk1N1YYNG+rdZ+DAgdq8ebMjke/evVsrV67U1Vdf7fLHZPEcAABuKC4uVnR0tOPn0NDQeueVlZXJarUqNjbWaTw2NlY7duyod59bbrlFZWVl+vWvfy273a66ujrdeeedtOIBADiDl1rx0dHRTtvZEntDrFmzRrNmzdKzzz6rLVu26M0339SKFSs0c+ZMl49BxQ4AMIZGfvJc69atFRISotLSUqfx0tJSxcXF1bvP1KlTddttt2nMmDGSpN69e6uyslL/+7//q4ceekhm87nrcSp2AAB8wGKxKCkpSYWFhY4xm82mwsJCpaSk1LvPyZMnz0jeISEhkiS73e7SeanYAQCGYDKZZGrkZ8VnZWUpPT1d/fv314ABA5Sbm6vKykplZGRIkkaPHq34+HjHArxhw4Zpzpw56tevn5KTk7Vz505NnTpVw4YNcyT4cyGxAwAMwR+JfeTIkTpy5Iiys7NVUlKixMRErVq1yrGgbt++fU4V+p/+9CeZTCb96U9/0oEDB3Teeedp2LBhevTRR10P0+5qbf8LVF5erpiYGIX2HitTiMXf4QA+8d2/nvF3CIDPlJeXK7ZVjI4fP+600tzb54iJiVH48HkyNQ1v8HHstf/Vf98e79NYvYGKHQBgDKbvN0/2DwAkdgCAIfijFe8PrIoHACCIULEDAAzBKBU7iR0AYAgkdgAAgohREjvX2AEACCJU7AAAY+B2NwAAggeteAAAEHCo2AEAhnDqra2eVOzei8WXSOwAAEMwycNWfIBkdlrxAAAEESp2AIAhGGXxHIkdAGAMBrndjVY8AABBhIodAGAMHrbi7bTiAQD45fD0GrtnK+obD4kdAGAIRknsXGMHACCIULEDAIzBIKviSewAAEOgFQ8AAAIOFTsAwBCMUrGT2AEAhmCUxE4rHgCAIELFDgAwBKNU7CR2AIAxGOR2N1rxAAAEESp2AIAh0IoHACCIkNgBAAgiRknsXGMHACCIULEDAIzBIKviSewAAEOgFQ8AAAIOid3gxvzP5fr8H9N1aN1TWv3CJF3cs+PPzr/z5sHauGSqDq6do23LZ+rRidcr1PJD4ycyIlSzsn6vf789QwfXztG7C7PUr2cHX38M4KwWvP6h+gzPVtylf1Tq7bO1+cu9Z527fdchjb5/gfoMz1aLSzI1/5UPzpjz8Zadumlinnpc9aBaXJKpFWs+92H08KbTFbsnW0PMmzdPnTp1UlhYmJKTk7Vx48azzh08eHC9573mmmtcPh+J3cCuu+JiPfLH6/Tn59/R4Nv+rG1fH9AbT49X6xaR9c6/Ia2/po2/Vo8veEfJNz6iu2e+rOuuSNLUccMdc/7yp1s0OLm77pz2oi69eZbe/2SHls67W23Pi2msjwU4vPneZv0p9y09MOYqrXnpAfW6IF6/v3uejhw9Ue/8/1bVqGN8a03LHK7YVtH1zjn532r1ujBes+8f6cvQ4QMmeZjYG3CRvaCgQFlZWZo2bZq2bNmivn37Ki0tTYcPH653/ptvvqlDhw45tm3btikkJET/8z//4/I5fxGJ3Z1vM/Cecbf8RouXrtcryz5R0Z4SZeW8ppNVNbp1eEq98wf06axP/71bS97dpOJDR/XBpzv0xnublHTRqSo/LLSphg9J1MNzl2r9Z7u0Z3+Z/rxgpXYXH9Effn9ZY340QJL07Cvva/SIgRo1PEXdu7TVnCk3KSLMor+9vaHe+Rdf1FEzJ1yn3w/tL4ul/iVIV1x6kf501zD9bkhfX4aOX7Dy8nKnrbq6+qxz58yZo7FjxyojI0M9e/ZUXl6eIiIilJ+fX+/8li1bKi4uzrGtXr1aERERgZXY3f02A+9o2iREid0TtGZjkWPMbrfrw41FuqR353r32fjvPUrsnuBo13eMb6UrBl6k1R9/KUlqEmJWkyYhqqqpddqvqrpWv0o830efBKhfTW2dtu4o1uAB3RxjZrNZgwZ007++2OPHyOAv3mrFJyQkKCYmxrHl5OTUe76amhpt3rxZqampjjGz2azU1FRt2FD/l8ufWrhwoW666SY1a9bM5c/p91XxP/42I0l5eXlasWKF8vPzNXnyZD9HF7xaNY9UkyYhZ7Qkjxwt1wWdYuvdZ8m7m9SyeTO98/xEmUwmNW0SovwlazVn0XuSpIqT1dr47926746r9NWeUh0+Wq4b0vrrkt6dtXv/EZ9/JuDHvj1WIavVpvNaRjmNn9cyWl/vLfVTVPArL93uVlxcrOjoHy7VhIaG1ju9rKxMVqtVsbHO/6bGxsZqx44d5zzdxo0btW3bNi1cuNCtMP1asbv7baa6uvqMFggaz6UXX6CsjDRN+nOBBt/6Z91631819NcXadIdVzrm/F/2YplM0vZ3HlXpx7n635GD9MZ7m2Sz2f0YOQB4T3R0tNN2tsTuqYULF6p3794aMGCAW/v5tWJ399tMTk6Opk+f3ljhBbVvj1Wors5abzVz+Nv6vzA9dOc1en3lRr30j1Nfuv6z66CahYfqqQdv1pP578put2vvgTL97v/+oogwi6Kahan023ItnJWhbw6U+fwzAT/WqnmkQkLM9Xal2pxlYRyCW2Pfx966dWuFhISotNS5Q1RaWqq4uLif3beyslKvvfaaZsyY4Xacfr/G7o4pU6bo+PHjjq24uNjfIQWs2jqrtu4o1qBLfrj+aDKZdPklF571+mN4mOWMyttqtX2/r/Pck1U1Kv22XDFR4frtr3po5UdfePcDAOdgadpEid0T9OG/flhHYrPZ9NG/vjrrOhIEt8a+3c1isSgpKUmFhYWOMZvNpsLCQqWk1L9I+bS///3vqq6u1q233ur25/Rrxe7ut5nQ0FCftTyM6NlX3tez027TZ9v3acuXe3XXzUPULDxULy/7RJI0/+HbdOjIcc2Y97YkadXabRp3yxD9u2i/Nn25V13an6cH7/ydVq39wpHwf/OrHjKZpK+/Oawu7c/TjAkj9NXeUr18llXIgC+Nu+U3Gjf9JfXr0UEXX9RJ81/9QJX/rdaoYb+SJN05bbHanhejaZnXSjq14K5od4kkqba2TgePHNMXRfvVLCJUXRLOk3RqLcme4h/WjHxz8Ft9UbRfzWMilBDXspE/IdxhMp1ZhLi7v7uysrKUnp6u/v37a8CAAcrNzVVlZaVjXdno0aMVHx9/xgK8hQsXasSIEWrVqpXb5/RrYv/xt5kRI0ZI+uHbTGZmpj9DM4S3Vm9R6+aRevD/rlGbVlH64qsDuuGeH+7xbR/XUjb7DxX6E/mrZLfb9dBdv1Pb82L07bEKrVq7TTOfXeaYEx0Zpuzxw9WuTXN9V35Sy97fqkeeXaa67yt7oDFdPzRJZccqNOu5FTr87Qn1vjBeS+aOd7Ti95cclflH/1qXHDmuy299zPHzM38r1DN/K9SlF3fV8uf+KEnauv0bDbtzrmPOQ0+9KUm6+ZpkPfvwbY3wqRBIRo4cqSNHjig7O1slJSVKTEzUqlWrHJeg9+3bJ7PZuXleVFSkdevW6b333mvQOU12u92vq5oKCgqUnp6u5557zvFt5vXXX9eOHTvOuPb+U+Xl5YqJiVFo77EyhVgaKWKgcX33r2f8HQLgM+Xl5YptFaPjx487rTT39jliYmLU5e4lMoe6ftvYT9mqK7X76Rt8Gqs3+P12t3N9mwEAwCs8bMXzdjc3ZGZm0noHAMALfhGJHQAAXzPKa1tJ7AAAQ/DHqnh/CKj72AEAwM+jYgcAGILZbJLZ3PCy2+7Bvo2JxA4AMARa8QAAIOBQsQMADIFV8QAABBGjtOJJ7AAAQzBKxc41dgAAgggVOwDAEIxSsZPYAQCGYJRr7LTiAQAIIlTsAABDMMnDVnyAvLeVxA4AMARa8QAAIOBQsQMADIFV8QAABBFa8QAAIOBQsQMADIFWPAAAQcQorXgSOwDAEIxSsXONHQCAIELFDgAwBg9b8QHy4DkSOwDAGGjFAwCAgEPFDgAwBFbFAwAQRGjFAwCAgEPFDgAwBFrxAAAEEVrxAAAg4FCxAwAMwSgVO4kdAGAIRrnGTiseAGAIpyt2T7aGmDdvnjp16qSwsDAlJydr48aNPzv/2LFjGj9+vNq2bavQ0FBdeOGFWrlypcvno2IHAMBHCgoKlJWVpby8PCUnJys3N1dpaWkqKipSmzZtzphfU1OjK664Qm3atNGSJUsUHx+vb775Rs2bN3f5nCR2AIAh+KMVP2fOHI0dO1YZGRmSpLy8PK1YsUL5+fmaPHnyGfPz8/N19OhRrV+/Xk2bNpUkderUya1z0ooHABiCt1rx5eXlTlt1dXW956upqdHmzZuVmprqGDObzUpNTdWGDRvq3eftt99WSkqKxo8fr9jYWPXq1UuzZs2S1Wp1+XOS2AEAcENCQoJiYmIcW05OTr3zysrKZLVaFRsb6zQeGxurkpKSevfZvXu3lixZIqvVqpUrV2rq1Kl68skn9cgjj7gcH614AIAhmORhK/77/xYXFys6OtoxHhoa6lFcP2az2dSmTRv99a9/VUhIiJKSknTgwAHNnj1b06ZNc+kYJHYAgCGYTSaZPcjsp/eNjo52Suxn07p1a4WEhKi0tNRpvLS0VHFxcfXu07ZtWzVt2lQhISGOsR49eqikpEQ1NTWyWCznjvOcMwAAgNssFouSkpJUWFjoGLPZbCosLFRKSkq9+1x66aXauXOnbDabY+yrr75S27ZtXUrqEokdAGAQp1fFe7K5KysrSwsWLNCLL76o7du366677lJlZaVjlfzo0aM1ZcoUx/y77rpLR48e1YQJE/TVV19pxYoVmjVrlsaPH+/yOWnFAwAMwR+PlB05cqSOHDmi7OxslZSUKDExUatWrXIsqNu3b5/M5h9q7ISEBL377ruaOHGi+vTpo/j4eE2YMEEPPPCAy+cksQMADMFsOrV5sn9DZGZmKjMzs97frVmz5oyxlJQUffLJJw07mWjFAwAQVKjYAQDGYPLwDW0B8hIYEjsAwBB4uxsAAAg4VOwAAEMwff/Hk/0DAYkdAGAI/loV39hoxQMAEESo2AEAhuCPB9T4A4kdAGAIRlkV71Jif/vtt10+4PDhwxscDAAA8IxLiX3EiBEuHcxkMslqtXoSDwAAPuGt17b+0rmU2H/8+jgAAAIRrXgXVFVVKSwszFuxAADgM0ZZPOf27W5Wq1UzZ85UfHy8IiMjtXv3bknS1KlTtXDhQq8HCAAAXOd2Yn/00Ue1aNEiPf7447JYLI7xXr166fnnn/dqcAAAeMvpVrwnWyBwO7EvXrxYf/3rXzVq1CiFhIQ4xvv27asdO3Z4NTgAALzl9OI5T7ZA4HZiP3DggLp27XrGuM1mU21trVeCAgAADeN2Yu/Zs6fWrl17xviSJUvUr18/rwQFAIC3mbywBQK3V8VnZ2crPT1dBw4ckM1m05tvvqmioiItXrxYy5cv90WMAAB4jFXxZ3Httddq2bJl+uc//6lmzZopOztb27dv17Jly3TFFVf4IkYAAOCiBt3Hftlll2n16tXejgUAAJ8xymtbG/yAmk2bNmn79u2STl13T0pK8lpQAAB4m1Fa8W4n9v379+vmm2/Wxx9/rObNm0uSjh07poEDB+q1115T+/btvR0jAABwkdvX2MeMGaPa2lpt375dR48e1dGjR7V9+3bZbDaNGTPGFzECAOAVwf5wGqkBFfuHH36o9evXq1u3bo6xbt266emnn9Zll13m1eAAAPAWWvFnkZCQUO+DaKxWq9q1a+eVoAAA8DajLJ5zuxU/e/Zs3X333dq0aZNjbNOmTZowYYKeeOIJrwYHAADc41LF3qJFC6cWRGVlpZKTk9Wkyand6+rq1KRJE/3hD3/QiBEjfBIoAACeoBX/I7m5uT4OAwAA3/L0sbCBkdZdTOzp6em+jgMAAHhBgx9QI0lVVVWqqalxGouOjvYoIAAAfMHTV68G7WtbKysrlZmZqTZt2qhZs2Zq0aKF0wYAwC+RJ/ewB9K97G4n9vvvv1/vv/++5s+fr9DQUD3//POaPn262rVrp8WLF/siRgAA4CK3W/HLli3T4sWLNXjwYGVkZOiyyy5T165d1bFjR7388ssaNWqUL+IEAMAjRlkV73bFfvToUXXp0kXSqevpR48elST9+te/1kcffeTd6AAA8BJa8WfRpUsX7dmzR5LUvXt3vf7665JOVfKnXwoDAAD8w+3EnpGRoc8//1ySNHnyZM2bN09hYWGaOHGi7rvvPq8HCACAN5xeFe/J1hDz5s1Tp06dFBYWpuTkZG3cuPGscxctWuS4ZHB6CwsLc+t8bl9jnzhxouN/p6amaseOHdq8ebO6du2qPn36uHs4AAAahaft9IbsW1BQoKysLOXl5Sk5OVm5ublKS0tTUVGR2rRpU+8+0dHRKioq+tF53TuxR/exS1LHjh3VsWNHTw8DAIBP+WPx3Jw5czR27FhlZGRIkvLy8rRixQrl5+dr8uTJZz1PXFxcg+N0KbHPnTvX5QPec889DQ4GAIBfuvLycqefQ0NDFRoaesa8mpoabd68WVOmTHGMmc1mpaamasOGDWc9fkVFhTp27CibzaaLL75Ys2bN0kUXXeRyfC4l9qeeesqlg5lMJr8k9iX5D6pZZFSjnxdoDIl/etffIQA+Y62ubLRzmdWAhWU/2V869fryH5s2bZoefvjhM+aXlZXJarUqNjbWaTw2NlY7duyo9xzdunVTfn6++vTpo+PHj+uJJ57QwIED9eWXX6p9+/YuxelSYj+9Ch4AgEDlrVZ8cXGx0+PT66vWGyolJUUpKSmOnwcOHKgePXroueee08yZM106hsfX2AEAMJLo6GiX3ovSunVrhYSEqLS01Gm8tLTU5WvoTZs2Vb9+/bRz506X4/OkKwEAQMAwmSSzB5u7xb7FYlFSUpIKCwsdYzabTYWFhU5V+c+xWq364osv1LZtW5fPS8UOADCE0wnak/3dlZWVpfT0dPXv318DBgxQbm6uKisrHavkR48erfj4eOXk5EiSZsyYoV/96lfq2rWrjh07ptmzZ+ubb77RmDFjXD4niR0AAB8ZOXKkjhw5ouzsbJWUlCgxMVGrVq1yLKjbt2+fzOYfmuffffedxo4dq5KSErVo0UJJSUlav369evbs6fI5SewAAEPw10tgMjMzlZmZWe/v1qxZ4/TzU0895fKdaGfToGvsa9eu1a233qqUlBQdOHBAkvTSSy9p3bp1HgUDAICveHJ93dM2fmNyO7G/8cYbSktLU3h4uD777DNVV1dLko4fP65Zs2Z5PUAAAOA6txP7I488ory8PC1YsEBNmzZ1jF966aXasmWLV4MDAMBbjPLaVrevsRcVFenyyy8/YzwmJkbHjh3zRkwAAHidJ29oO71/IHC7Yo+Li6v3Rvl169apS5cuXgkKAABvM3thCwRuxzl27FhNmDBBn376qUwmkw4ePKiXX35ZkyZN0l133eWLGAEAgIvcbsVPnjxZNptNv/3tb3Xy5EldfvnlCg0N1aRJk3T33Xf7IkYAADzmj/ex+4Pbid1kMumhhx7Sfffdp507d6qiokI9e/ZUZGSkL+IDAMArzPLwGrsCI7M3+AE1FovFrSfhAAAA33M7sQ8ZMuRnn77z/vvvexQQAAC+QCv+LBITE51+rq2t1datW7Vt2zalp6d7Ky4AALzKHy+B8Qe3E/vZnmH78MMPq6KiwuOAAABAw3nttrxbb71V+fn53jocAABedep97KYGb0Hbij+bDRs2KCwszFuHAwDAq7jGfhbXX3+90892u12HDh3Spk2bNHXqVK8FBgAA3Od2Yo+JiXH62Ww2q1u3bpoxY4aGDh3qtcAAAPAmFs/Vw2q1KiMjQ71791aLFi18FRMAAF5n+v6PJ/sHArcWz4WEhGjo0KG8xQ0AEHBOV+yebIHA7VXxvXr10u7du30RCwAA8JDbif2RRx7RpEmTtHz5ch06dEjl5eVOGwAAv0RGqdhdvsY+Y8YM3Xvvvbr66qslScOHD3d6tKzdbpfJZJLVavV+lAAAeMhkMv3sI9Fd2T8QuJzYp0+frjvvvFMffPCBL+MBAAAecDmx2+12SdKgQYN8FgwAAL7C7W71CJQ2BAAAP8WT5+px4YUXnjO5Hz161KOAAABAw7mV2KdPn37Gk+cAAAgEp1/m4sn+gcCtxH7TTTepTZs2vooFAACfMco1dpfvY+f6OgAAv3xur4oHACAgebh4LkAeFe96YrfZbL6MAwAAnzLLJLMH2dmTfRuT269tBQAgEBnldje3nxUPAAB+uajYAQCGYJRV8SR2AIAhGOU+dlrxAAAEESp2AIAhGGXxHIkdAGAIZnnYig+Q291oxQMA4EPz5s1Tp06dFBYWpuTkZG3cuNGl/V577TWZTCaNGDHCrfOR2AEAhnC6Fe/J5q6CggJlZWVp2rRp2rJli/r27au0tDQdPnz4Z/fbu3evJk2apMsuu8ztc5LYAQCGYPbCJknl5eVOW3V19VnPOWfOHI0dO1YZGRnq2bOn8vLyFBERofz8/LPuY7VaNWrUKE2fPl1dunRp0OcEAAAuSkhIUExMjGPLycmpd15NTY02b96s1NRUx5jZbFZqaqo2bNhw1uPPmDFDbdq00R133NGg+Fg8BwAwBJPJ5NGbSk/vW1xcrOjoaMd4aGhovfPLyspktVoVGxvrNB4bG6sdO3bUu8+6deu0cOFCbd26tcFxktgBAIZgkmcvaDu9b3R0tFNi95YTJ07otttu04IFC9S6desGH4fEDgAwhMZ+8lzr1q0VEhKi0tJSp/HS0lLFxcWdMX/Xrl3au3evhg0b5hg7/WbVJk2aqKioSOeff/6543QrSgAA4BKLxaKkpCQVFhY6xmw2mwoLC5WSknLG/O7du+uLL77Q1q1bHdvw4cM1ZMgQbd26VQkJCS6dl4odAGAYjf2ImaysLKWnp6t///4aMGCAcnNzVVlZqYyMDEnS6NGjFR8fr5ycHIWFhalXr15O+zdv3lySzhj/OSR2AIAh+OORsiNHjtSRI0eUnZ2tkpISJSYmatWqVY4Fdfv27ZPZ7N3mOYkdAAAfyszMVGZmZr2/W7Nmzc/uu2jRIrfPR2IHABiCt253+6UjsQMADOHHT49r6P6BIFDiBAAALqBiBwAYAq14AACCiLeePPdLRyseAIAgQsUOADAEWvEAAAQRo6yKJ7EDAAzBKBV7oHwBAQAALqBiBwAYglFWxZPYAQCG4I+XwPgDrXgAAIIIFTsAwBDMMsnsQUPdk30bE4kdAGAItOIBAEDAoWIHABiC6fs/nuwfCEjsAABDoBUPAAACDhU7AMAQTB6uiqcVDwDAL4hRWvEkdgCAIRglsXONHQCAIELFDgAwBG53AwAgiJhNpzZP9g8EtOIBAAgiVOwAAEOgFQ8AQBBhVTwAAAg4VOwAAEMwybN2eoAU7CR2AIAxsCoeAAAEHCp2g1v23qd6Y9l6fXe8Qp07xOqu269Wt67t65378cb/qGDpWh0qPao6q1Xxca103TUD9dvL+kqS6uqsWvx6of619WuVHP5OzcLDlNi7izJuSlWrltGN+bEAh5HJCUr/dWe1irToq5IT+vPyHdp24PhZ50eFNVFm6gX6zUWxiglvqkPH/qvZK3do3Vdlkk5VbXf+pquuSWyrVpGhOnKiWm9vOaAFa3Y31kdCA7EqHkHvww3btOCld5V5xzB17xqvpe98oqmPvaS/Pnm3msdEnjE/KjJcN113udq3a62mTUL06ZYiPZW3VM2jmympb1dV19Rq555Duvm6QerSMU4Vlf9V3ovvaPoTr2rurP/zwyeE0Q3tFad7r+quR9/+Ul8UH9eogR317O1JujZ3nb6rrDljfpMQk/Ju76+jlTW679WtOlxepbbNw3Wiqs4xJ+PyzvqfAQnKfuML7TpcoZ7xMZp+fS9VVNXp1U/2NebHg5tYFd8IPvroIw0bNkzt2rWTyWTS0qVL/RmO4by1Yr2u/E2Shg7upw7t2yjzjt8p1NJU7635rN75fXp21sBLeqhD/HlqG9tSI65KUecOsfqy6BtJUrOIMM16KF2Xp/RS+3at1f2CBI3LuEY79xzU4bJjjfjJgFNuu7Sj3ty0X//YclC7j1Tqkbf/o6paq0Ykxdc7f8TF8YqOaKqJL3+mrfuO6eCxKm3e+52+KjnhmNM3obnW7DistV+V6eCxKv3zy1Jt2PmterWPaayPhQYyeWELBH5N7JWVlerbt6/mzZvnzzAMqbauTjv3HFJiry6OMbPZrMReXbTj6+Jz7m+327V1227tP1SmXt07nXVe5ckqmUwmRUaEeSNswGVNQkzq0S5an+761jFmt0uf7vpWfRKa17vP4O5t9O99xzRlWA8VTh6sJXcP1B2DOjstmvq8+JiSu7RSh1YRkqQL46LUr2Nzffx1mS8/DuAyv7bir7rqKl111VUuz6+urlZ1dbXj5/Lycl+EZQjl5Sdls9nU4ict9+YxkSo+ePZ/oCpPVum2cU+qtq5OZrNZ4zOu0cV9zq93bk1NrV54dbUGDeylCBI7GlmLCIuahJj1bUW10/i3FTXq1LpZvfvEtwzXJc1bauW/Dylz8RYltIzQg8N7qInZrOc+2CVJyv9oj5qFNtHSCb+W1W5XiMmkZ/75tVZ+fsjnnwmeMcskswf9dHMDa/Z58+Zp9uzZKikpUd++ffX0009rwIAB9c598803NWvWLO3cuVO1tbW64IILdO+99+q2225z+XwBdY09JydH06dP93cYhhYeZtEzj92p/1bV6PNtu7Xgb+8qLraF+vTs7DSvrs6qnL/8XXa7lPmH3/kpWsA9ZpNJRytrNHPpl7LZpe0Hy9UmOlTpl3V2JPahveJ0dd+2mvL3f2vX4Qp1axul+67uriMnqrXss4N+/gT4OZ620xuyb0FBgbKyspSXl6fk5GTl5uYqLS1NRUVFatOmzRnzW7ZsqYceekjdu3eXxWLR8uXLlZGRoTZt2igtLc2lcwbU7W5TpkzR8ePHHVtx8blbxqhfdHSEzGazvjte4TR+7HiFWjY/c+HcaWazWe3iWun8Tm11/e8u1aXJPfX6P9Y6zTmV1F/X4bJjevTB0VTr8IvvTtaozmpTq8hQp/FWkRaVVZy5cE6Sjpyo1jffnpTN/sPYniOVOi8qVE1CTv2zPvHKC/XCR3v07hcl2llaoRVbD+lv67/RHy7vXO8xEXzKy8udth93kn9qzpw5Gjt2rDIyMtSzZ0/l5eUpIiJC+fn59c4fPHiwrrvuOvXo0UPnn3++JkyYoD59+mjdunUuxxdQiT00NFTR0dFOGxqmaZMm6tq5rT7f9sMtOjabTVu/3KPuFyS4fBy7za7aWqvj59NJ/WDJUc16KF3RURFejRtwVZ3Vru0HyzWgS0vHmMkkDejSSv8uPlbvPp/vO6YOLSOcVj93bB2hw+VVqrOeyvZhTUOcEr8k2Wx2j1q8aCReWj2XkJCgmJgYx5aTk1Pv6WpqarR582alpqY6xsxms1JTU7Vhw4Zzhmu321VYWKiioiJdfvnlLn/MgGrFw7uuu2ag5sx/Sxd0ideFXeP1j3c2qLq6RlcM6idJeuLZN9WqRZQybr5CklSw9CNd0CVebWNbqLbOqk2ffaX3132u8d+32uvqrJqVW6Cdew7p4ftHyWqz6eixU6uJoyLD1bQJf93QuF76+BvN/H0v/edgubbtP3W7W7glRP/YfECSNPP3vXS4vFpPr/5akvT6xmKNTO6g+6/urlc/2aeOrSJ0x6AuenXDD7exfbTjiMYM6qKSY//9vhUfrVsv7eQ4Jn65vHUfe3FxsVNhGRoaWu/8srIyWa1WxcbGOo3HxsZqx44dZz3P8ePHFR8fr+rqaoWEhOjZZ5/VFVdc4XKc/EtrYINSeqm8vFIvLXlf3x2rUJeOcZox+Ta1+L4Vf6TsuFMVUlVdq2dfWK6yb8tlsTRVQrvWmjT+9xqU0kuS9O135fpkc5EkKXPyfKdzPTb19jOuwwO+9t62ErVoZtFdv+2q1pGhKjpUrnEvbtbR7+9hb9s8XPYfVd+lx6s07sVNmnR1d/09c6AOn6jWKxu+0Qsf7XHMeWz5do1PvUBThvdUy2YWHTlRrTf+Vey4Bo/g5+uOcVRUlLZu3aqKigoVFhYqKytLXbp00eDBg13a32S32+3nnuYbFRUV2rlzpySpX79+mjNnjoYMGaKWLVuqQ4cO59y/vLxcMTExWvavPWoWGeXrcAG/uGvRJn+HAPiMtbpSO3N/r+PHj/ssWZ7OFYVb9ykyquHnqDhRrt8mdnA51pqaGkVERGjJkiUaMWKEYzw9PV3Hjh3TP/7xD5fOO2bMGBUXF+vdd991ab5fr7Fv2rRJ/fr1U79+p1q/WVlZ6tevn7Kzs/0ZFgAgCDX2A2osFouSkpJUWFjoGLPZbCosLFRKSorLx7HZbD+7QO+n/NqKHzx4sPzYMAAAwKeysrKUnp6u/v37a8CAAcrNzVVlZaUyMjIkSaNHj1Z8fLxjAV5OTo769++v888/X9XV1Vq5cqVeeuklzZ8//+dO44Rr7AAAY/DDjewjR47UkSNHlJ2drZKSEiUmJmrVqlWOBXX79u2T2fxD87yyslLjxo3T/v37FR4eru7du+tvf/ubRo4c6XqY/rzG7imuscMIuMaOYNaY19g/+LzY42vsQ/om+DRWb6BiBwAYAm93AwAAAYeKHQBgCP54Vrw/kNgBAMZgkMxOKx4AgCBCxQ4AMARvPSv+l47EDgAwBFbFAwCAgEPFDgAwBIOsnSOxAwAMwiCZnVY8AABBhIodAGAIrIoHACCIGGVVPIkdAGAIBrnEzjV2AACCCRU7AMAYDFKyk9gBAIZglMVztOIBAAgiVOwAAENgVTwAAEHEIJfYacUDABBMqNgBAMZgkJKdxA4AMARWxQMAgIBDxQ4AMARWxQMAEEQMcomdxA4AMAiDZHausQMAEESo2AEAhmCUVfEkdgCAMXi4eC5A8jqteAAAggkVOwDAEAyydo7EDgAwCINkdlrxAAAEESp2AIAhsCoeAIAgYpRHytKKBwDAh+bNm6dOnTopLCxMycnJ2rhx41nnLliwQJdddplatGihFi1aKDU19Wfn14fEDgAwBJMXNncVFBQoKytL06ZN05YtW9S3b1+lpaXp8OHD9c5fs2aNbr75Zn3wwQfasGGDEhISNHToUB04cMDlc5LYAQDG4IfMPmfOHI0dO1YZGRnq2bOn8vLyFBERofz8/Hrnv/zyyxo3bpwSExPVvXt3Pf/887LZbCosLHT5nCR2AIAhmLzwR5LKy8udturq6nrPV1NTo82bNys1NdUxZjablZqaqg0bNrgU88mTJ1VbW6uWLVu6/DlJ7AAAuCEhIUExMTGOLScnp955ZWVlslqtio2NdRqPjY1VSUmJS+d64IEH1K5dO6cvB+fCqngAgCGY5OGq+O//W1xcrOjoaMd4aGioR3GdzWOPPabXXntNa9asUVhYmMv7kdgBAIbgrQfPRUdHOyX2s2ndurVCQkJUWlrqNF5aWqq4uLif3feJJ57QY489pn/+85/q06ePW3HSigcAwAcsFouSkpKcFr6dXgiXkpJy1v0ef/xxzZw5U6tWrVL//v3dPi8VOwDAEPzxgJqsrCylp6erf//+GjBggHJzc1VZWamMjAxJ0ujRoxUfH++4Tv/nP/9Z2dnZeuWVV9SpUyfHtfjIyEhFRka6dE4SOwDAIBr/LTAjR47UkSNHlJ2drZKSEiUmJmrVqlWOBXX79u2T2fxD83z+/PmqqanRDTfc4HScadOm6eGHH3bpnCR2AAB8KDMzU5mZmfX+bs2aNU4/79271+PzkdgBAIZglGfFk9gBAIZgkNexsyoeAIBgQsUOADAEWvEAAASRHz/vvaH7BwISOwDAGAxykZ1r7AAABBEqdgCAIRikYCexAwCMwSiL52jFAwAQRKjYAQCGwKp4AACCiUEustOKBwAgiFCxAwAMwSAFO4kdAGAMrIoHAAABh4odAGAQnq2KD5RmPIkdAGAItOIBAEDAIbEDABBEaMUDAAzBKK14EjsAwBCM8khZWvEAAAQRKnYAgCHQigcAIIgY5ZGytOIBAAgiVOwAAGMwSMlOYgcAGAKr4gEAQMChYgcAGAKr4gEACCIGucROYgcAGIRBMjvX2AEACCJU7AAAQzDKqngSOwDAEFg8FwDsdrsk6WTFCT9HAviOtbrS3yEAPmOrPinph3/Pfam8vNyv+zeWgE7sJ06cSugjh/TxcyQAAE+cOHFCMTExPjm2xWJRXFycLuic4PGx4uLiZLFYvBCV75jsjfE1yUdsNpsOHjyoqKgomQKlRxLgysvLlZCQoOLiYkVHR/s7HMCr+Pvd+Ox2u06cOKF27drJbPbdeu6qqirV1NR4fByLxaKwsDAvROQ7AV2xm81mtW/f3t9hGFJ0dDT/8CFo8fe7cfmqUv+xsLCwX3xC9hZudwMAIIiQ2AEACCIkdrglNDRU06ZNU2hoqL9DAbyOv98IBgG9eA4AADijYgcAIIiQ2AEACCIkdgAAggiJHQCAIEJih8vmzZunTp06KSwsTMnJydq4caO/QwK84qOPPtKwYcPUrl07mUwmLV261N8hAQ1GYodLCgoKlJWVpWnTpmnLli3q27ev0tLSdPjwYX+HBnissrJSffv21bx58/wdCuAxbneDS5KTk3XJJZfomWeekXTqOf0JCQm6++67NXnyZD9HB3iPyWTSW2+9pREjRvg7FKBBqNhxTjU1Ndq8ebNSU1MdY2azWampqdqwYYMfIwMA/BSJHedUVlYmq9Wq2NhYp/HY2FiVlJT4KSoAQH1I7AAABBESO86pdevWCgkJUWlpqdN4aWmp4uLi/BQVAKA+JHack8ViUVJSkgoLCx1jNptNhYWFSklJ8WNkAICfauLvABAYsrKylJ6erv79+2vAgAHKzc1VZWWlMjIy/B0a4LGKigrt3LnT8fOePXu0detWtWzZUh06dPBjZID7uN0NLnvmmWc0e/ZslZSUKDExUXPnzlVycrK/wwI8tmbNGg0ZMuSM8fT0dC1atKjxAwI8QGIHACCIcI0dAIAgQmIHACCIkNgBAAgiJHYAAIIIiR0AgCBCYgcAIIiQ2AEACCIkdgAAggiJHfDQ7bffrhEjRjh+Hjx4sP74xz82ehxr1qyRyWTSsWPHzjrHZDJp6dKlLh/z4YcfVmJiokdx7d27VyaTSVu3bvXoOABcQ2JHULr99ttlMplkMplksVjUtWtXzZgxQ3V1dT4/95tvvqmZM2e6NNeVZAwA7uAlMAhaV155pV544QVVV1dr5cqVGj9+vJo2baopU6acMbempkYWi8Ur523ZsqVXjgMADUHFjqAVGhqquLg4dezYUXfddZdSU1P19ttvS/qhff7oo4+qXbt26tatmySpuLhYN954o5o3b66WLVvq2muv1d69ex3HtFqtysrKUvPmzdWqVSvdf//9+unrFn7aiq+urtYDDzyghIQEhYaGqmvXrlq4cKH27t3rePFIixYtZDKZdPvtt0s69VrcnJwcde7cWeHh4erbt6+WLFnidJ6VK1fqwgsvVHh4uIYMGeIUp6seeOABXXjhhYqIiFCXLl00depU1dbWnjHvueeeU0JCgiIiInTjjTfq+PHjTr9//vnn1aNHD4WFhal79+569tln3Y4FgHeQ2GEY4eHhqqmpcfxcWFiooqIirV69WsuXL1dtba3S0tIUFRWltWvX6uOPP1ZkZKSuvPJKx35PPvmkFi1apPz8fK1bt05Hjx7VW2+99bPnHT16tF599VXNnTtX27dv13PPPafIyEglJCTojTfekCQVFRXp0KFD+stf/iJJysnJ0eLFi5WXl6cvv/xSEydO1K233qoPP/xQ0qkvINdff72GDRumrVu3asyYMZo8ebLb/59ERUVp0aJF+s9//qO//OUvWrBggZ566imnOTt37tTrr7+uZcuWadWqVfrss880btw4x+9ffvllZWdn69FHH9X27ds1a9YsTZ06VS+++KLb8QDwAjsQhNLT0+3XXnut3W632202m3316tX20NBQ+6RJkxy/j42NtVdXVzv2eemll+zdunWz22w2x1h1dbU9PDzc/u6779rtdru9bdu29scff9zx+9raWnv79u0d57Lb7fZBgwbZJ0yYYLfb7faioiK7JPvq1avrjfODDz6wS7J/9913jrGqqip7RESEff369U5z77jjDvvNN99st9vt9ilTpth79uzp9PsHHnjgjGP9lCT7W2+9ddbfz549256UlOT4edq0afaQkBD7/v37HWPvvPOO3Ww22w8dOmS32+32888/3/7KK684HWfmzJn2lJQUu91ut+/Zs8cuyf7ZZ5+d9bwAvIdr7Ahay5cvV2RkpGpra2Wz2XTLLbfo4Ycfdvy+d+/eTtfVP//8c+3cuVNRUVFOx6mqqtKuXbt0/PhxHTp0yOkd9E2aNFH//v3PaMeftnXrVoWEhGjQoEEux71z506dPHlSV1xxhdN4TU2N+vXrJ0navn27UxySlJKS4vI5TisoKNDcuXO1a9cuVVRUqK6uTtHR0U5zOnTooPj4eKfz2Gw2FRUVKSoqSrt27dIdd9yhsWPHOubU1dUpJibG7XgAeI7EjqA1ZMgQzZ8/XxaLRe3atVOTJs5/3Zs1a+b0c0VFhZKSkvTyyy+fcazzzjuvQTGEh4e7vU9FRYUkacWKFU4JVTq1bsBbNmzYoFGjRmn69OlKS0tTTEyMXnvtNT355JNux7pgwYIzvmiEhIR4LVYAriOxI2g1a9ZMXbt2dXn+xRdfrIKCArVp0+aMqvW0tm3b6tNPP9Xll18u6VRlunnzZl188cX1zu/du7dsNps+/PBDpaamnvH70x0Dq9XqGOvZs6dCQ0O1b9++s1b6PXr0cCwEPO2TTz4594f8kfXr16tjx4566KGHHGPffPPNGfP27dungwcPql27do7zmM1mdevWTbGxsWrXrp12796tUaNGuXV+AL7B4jnge6NGjVLr1q117bXXau3atdqzZ4/WrFmje+65R/v375ckTZgwQY899piWLl2qHTt2aNy4cT97D3qnTp2Unp6uP/zhD1q6dKnjmK+//rokqWPHjjKZTFq+fLmOHDmiiooKRUVFadKkSZo4caJefPFF7dq1S1u2bNHTTz/tWJB255136uuvv9Z9992noqIivfLKK1q0aJFbn/eCCy7Qvn379Nprr2nXrl2aO3duvQsBw8LClJ6ers8//1xr167VPffcoxtvvFFxcXGSpOnTpysnJ0dz587VV199pS+++EIvvPCC5syZ41Y8ALyDxA58LyIiQh999JE6dOig66+/Xj169NAdd9yhqqoqRwV/77336rbbblN6erpSUlIUFRWl66677mePO3/+fN1www0aN26cunfvrrFjx6qyslKSFB8fr+nTp2vy5MmKjY1VZmamJGnmzJmaOnWqcnJy1KNHD1155ZVasWKFOnfuLOnUde833nhDS5cuVd++fZWXl6dZs2a59XmHDx+uiRMnKjMzU4mJiVq/fr2mTp16xryuXbvq+uuv19VXX62hQ4eqT58+TrezjRkzRs8//7xeeOEF9e7dW4MGDdKiRYscsQJoXCb72Vb9AACAgEPFDgBAECGxAwAQREjsAAAEERI7AABBhMQOAEAQIbEDABBESOwAAAQREjsAAEGExA4AQBAhsQMAEERI7AAABJH/B7N3jE6Tzu68AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def grid_parameters(parameters):\n",
    "    for params in product(*parameters.values()):\n",
    "        yield dict(zip(parameters.keys(), params))\n",
    "\n",
    "parameters = {\n",
    "    'clf': [\n",
    "        LogisticRegression(max_iter=2000, random_state=42),\n",
    "        RandomForestClassifier(max_depth=250, random_state=42), # Informed guess at max_depth\n",
    "        SGDClassifier(max_iter=2000, random_state=42),\n",
    "        SVC(max_iter=2000, random_state=42),\n",
    "        LinearSVC(max_iter=2000, random_state=42),\n",
    "        MultinomialNB(),\n",
    "    ],\n",
    "    'tfidf': [True, False],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for settings in grid_parameters(parameters):\n",
    "    f1_macro = evaluate_preprocessing(train_df, **settings, verbose=False)\n",
    "    results.append((settings, f1_macro))\n",
    "\n",
    "best_result = max(results, key=lambda x: x[1])\n",
    "print(\"Best result:\\n\", best_result)\n",
    "\n",
    "evaluate_preprocessing(train_df, **best_result[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 models:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'clf': SVC(max_iter=2000, random_state=42),\n",
       "   'tfidf': False,\n",
       "   'ngram_range': (1, 1)},\n",
       "  0.789233228475146),\n",
       " ({'clf': SVC(max_iter=2000, random_state=42),\n",
       "   'tfidf': True,\n",
       "   'ngram_range': (1, 1)},\n",
       "  0.7844887644132201),\n",
       " ({'clf': MultinomialNB(), 'tfidf': True, 'ngram_range': (1, 3)},\n",
       "  0.7812398369577)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Top 3 models:')\n",
    "sorted(results, key=lambda x: x[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of results\n",
    "\n",
    "We evaluated the effect of additional feature engineering:\n",
    "* TF-IDF weighting\n",
    "* Bigrams\n",
    "* Trigrams\n",
    "\n",
    "And several different ML models:\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* SGD\n",
    "* SVC\n",
    "* Linear SVC\n",
    "* Multinomial Naive Bayes\n",
    "\n",
    "The best results came from the model we already obtained in the previous notebook:\n",
    "\n",
    "**A simple bag of words model with Logistic Regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the model\n",
    "\n",
    "*(Copied from previous notebook with modifications to use the Pipeline)*\n",
    "\n",
    "An advantage of the bag of words + logistic regression model is its simplicity.\n",
    "\n",
    "We can simply look up the model coefficients to determine feature importance:\n",
    "* Which words contribute to a classification of \"disaster\" (1) or \"non-disaster\" (0)?\n",
    "\n",
    "There is no need to scale the coefficients here since all the features are from the BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following words have the highest positive coefficients (disaster):\n",
      "            Coefficients\n",
      "hiroshima       2.445416\n",
      "wildfire        2.359061\n",
      "earthquake      2.220706\n",
      "derailment      2.186881\n",
      "fires           2.132240\n",
      "tornado         1.992465\n",
      "riots           1.907593\n",
      "suicide         1.897605\n",
      "massacre        1.870264\n",
      "floods          1.869637\n",
      "\n",
      "The following words have the most negative coefficients (non-disaster):\n",
      "        Coefficients\n",
      "full       -1.564929\n",
      "better     -1.506215\n",
      "blight     -1.411568\n",
      "ebay       -1.404008\n",
      "bags       -1.243934\n",
      "cake       -1.237400\n",
      "upon       -1.234887\n",
      "show       -1.211611\n",
      "art        -1.197938\n",
      "likely     -1.184574\n"
     ]
    }
   ],
   "source": [
    "pipeline, X_train, X_val, y_train, y_val = evaluate_preprocessing(\n",
    "    train_df, **best_result[0], return_artifacts=True\n",
    ")\n",
    "\n",
    "model_coefficients = pd.DataFrame(\n",
    "   pipeline['clf'].coef_.T,\n",
    "   columns=['Coefficients'], index=pipeline['vect'].get_feature_names_out()\n",
    ")\n",
    "\n",
    "sorted_words = model_coefficients.sort_values('Coefficients', ascending=False)\n",
    "print('The following words have the highest positive coefficients (disaster):')\n",
    "print(sorted_words.head(10).to_string())\n",
    "\n",
    "print('\\nThe following words have the most negative coefficients (non-disaster):')\n",
    "print(sorted_words.tail(10)[::-1].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaining a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_explain(tweet, pipeline, settings):\n",
    "    \"\"\"Predict the class of a tweet and explain the prediction.\"\"\"\n",
    "    bow = pipeline['vect'].transform([tweet])\n",
    "    prediction = pipeline['clf'].predict(bow)[0]\n",
    "    word_importance = []\n",
    "    \n",
    "    # Get words from bow\n",
    "    words = pipeline['vect'].get_feature_names_out()\n",
    "\n",
    "    # Get model coefficients\n",
    "    coefficients = pipeline['clf'].coef_[0]\n",
    "\n",
    "    # Get coefficients for words in the tweet\n",
    "    for i, word in enumerate(words):\n",
    "        if bow[0, i] > 0:\n",
    "            word_importance.append((word, coefficients[i]))\n",
    "\n",
    "    word_importance = sorted(word_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f'Prediction: {\"disaster\" if prediction == 1 else \"non-disaster\"}\\n')\n",
    "    for word, coefficient in word_importance:\n",
    "        print(f'{word}: {coefficient:.2f}')\n",
    "    \n",
    "    return prediction, word_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So apparently there were bush fires near where I live over the weekend that I was totally oblivious to... \n",
      "\n",
      "Prediction: disaster\n",
      "\n",
      "fires: 2.13\n",
      "near: 0.95\n",
      "were: 0.81\n",
      "over: 0.71\n",
      "bush: 0.49\n",
      "was: 0.35\n",
      "apparently: 0.28\n",
      "that: 0.07\n",
      "totally: -0.01\n",
      "there: -0.01\n",
      "live: -0.02\n",
      "where: -0.37\n",
      "weekend: -0.41\n",
      "so: -0.49\n"
     ]
    }
   ],
   "source": [
    "tweet = train_df['text'].sample(1).values[0]\n",
    "print(tweet, '\\n')\n",
    "\n",
    "prediction, word_importance = predict_and_explain(tweet, pipeline, best_result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ec6_exam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32d7a0e0701bdeeaab07027fb8273d1e6dc5f66c0a91a8b21fdaab4a83de9cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
