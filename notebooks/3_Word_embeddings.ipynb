{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Fellowship program exam\n",
    "\n",
    "**Machine Learning - Assignment 2: Natural disasters dataset**\n",
    "\n",
    "By: Jules Kuehn\n",
    "\n",
    "Due: 2020-12-03, 6pm Eastern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Pre-trained word embeddings + linear classifier model\n",
    "\n",
    "Not implemented, but would be nice:\n",
    "* Common functions moved to python module, to be imported into multiple notebooks.\n",
    "* (Some code is duplicated here from the previous notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import re\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "Use Pandas to import the CSV to a Dataframe. For a larger dataset, I would use Spark for pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "disaster_tweets = train_df[train_df['target'] == 1]['text'].tolist()\n",
    "non_disaster_tweets = train_df[train_df['target'] == 0]['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed tweets into W-dimensional vector\n",
    "\n",
    "This is trivially easy with spacy.\n",
    "\n",
    "However, we may want to try a few different methods.\n",
    "\n",
    "Since our pre-processing (lowercasing, punctuation stripping) is no longer handled by CountVectorizer, that should be added back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(\n",
    "    texts,\n",
    "    replace_numbers=True,\n",
    "    replace_mentions=True,\n",
    "    replace_hashtags=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess texts for NLP.\n",
    "    Takes a list or Series of texts and returns a list of preprocessed texts.\n",
    "    \"\"\"\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.tolist()\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        if replace_numbers:\n",
    "            # Replace any substring of digits with ' number ' using regex\n",
    "            text = re.sub(r'\\d+', ' number ', text)\n",
    "        if replace_mentions:\n",
    "            # For pre-trained embeddings, we want to use common words\n",
    "            text = text.replace('@', ' at ')\n",
    "        if replace_hashtags:\n",
    "            text = text.replace('#', ' hashtag ')\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        # Remove punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove leading and trailing whitespace\n",
    "        text = text.strip()\n",
    "        texts[i] = text\n",
    "    return texts\n",
    "\n",
    "train_df['processed_text'] = preprocess_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacy document embedding\n",
    "\n",
    "The advantage of getting an embedding for a single document is ease of use, but it is not as interpretable or flexible as per-word embeddings. (This is the mean vector of the text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 96)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_text_spacy(texts, model):\n",
    "    \"\"\"\n",
    "    Embed a list of text using a spacy model.\n",
    "    \"\"\"\n",
    "    return np.array([model(text).vector for text in texts])\n",
    "\n",
    "# Load the spacy model\n",
    "# Note: better performance with larger models, but slower to load\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Embed the tweets\n",
    "tweets_embedded_spacy = embed_text_spacy(train_df['text'], nlp)\n",
    "\n",
    "tweets_embedded_spacy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10663193, -0.06177586,  0.01677806, ...,  0.15290211,\n",
       "        -0.06339556,  0.06228748],\n",
       "       [ 0.35435182, -0.06206617, -0.13854524, ..., -0.01496623,\n",
       "        -0.01122114, -0.4016894 ],\n",
       "       [ 0.15765142,  0.03518435,  0.06658074, ...,  0.01935729,\n",
       "        -0.15030086,  0.05764329],\n",
       "       ...,\n",
       "       [-0.09609085, -0.42296267, -0.10893895, ..., -0.37544906,\n",
       "         0.06502324, -0.6771796 ],\n",
       "       [ 0.09619114, -0.01231611,  0.1896926 , ...,  0.13207202,\n",
       "        -0.2183739 , -0.2528774 ],\n",
       "       [ 0.08932912, -0.16393521,  0.17910671, ...,  0.364201  ,\n",
       "         0.06129225,  0.19030449]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does the preprocessing make a difference?\n",
    "clean_tweets_embedded_spacy = embed_text_spacy(train_df['processed_text'], nlp)\n",
    "\n",
    "clean_tweets_embedded_spacy - tweets_embedded_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacy word embeddings (concatenated)\n",
    "\n",
    "We can also obtain a single W-dimensional vector from simply concatenating the word embeddings (and padding or trimming the vector to W). This doesn't seem like a good idea (due to loss of word boundaries, vs. a multidimensional model where each word is a vector), but we can try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 960)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_text_spacy_per_word(texts, model):\n",
    "    \"\"\"\n",
    "    Embed a list of text using a spacy model.\n",
    "    \"\"\"\n",
    "    embedded_texts = []\n",
    "    for text in texts:\n",
    "        word_embeddings = np.array([token.vector for token in model(text)])\n",
    "        # Concatenate the word embeddings\n",
    "        concat_embedding = np.concatenate(word_embeddings, axis=0)\n",
    "        # Pad or trim the embedding to a fixed length\n",
    "        padded_embedding = np.pad(concat_embedding, 960)\n",
    "        truncated_embedding = padded_embedding[:960]\n",
    "        embedded_texts.append(truncated_embedding)\n",
    "    \n",
    "    return np.array(embedded_texts)\n",
    "\n",
    "# Embed the tweets\n",
    "tweets_embedded_spacy_per_word = embed_text_spacy_per_word(\n",
    "    train_df['text'], nlp\n",
    ")\n",
    "\n",
    "# Embed the cleaned tweets\n",
    "clean_tweets_embedded_spacy_per_word = embed_text_spacy_per_word(\n",
    "    train_df['processed_text'], nlp\n",
    ")\n",
    "\n",
    "tweets_embedded_spacy_per_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and evaluation\n",
    "\n",
    "Note that I am not using the test data at this time. I am only using the training data while testing pre-processing hyperparameters.\n",
    "\n",
    "(We will use the test data in the last task of this exam, to compare all models.)\n",
    "\n",
    "This code is largely the same as in notebook 1_BoW, but with the TF-IDF transformer added and manual pre-processing steps removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preprocessing(\n",
    "    train_df,\n",
    "    strip_accents='ascii',\n",
    "    lowercase=True,\n",
    "    initial_vocab='all',\n",
    "    remove_n_common_words=5,\n",
    "    min_df=5,\n",
    "    max_features=None,\n",
    "    verbose=False,\n",
    "    return_artifacts=False,\n",
    "    ngram_range=(1, 1),\n",
    "    use_idf=True,\n",
    "    norm='l2',\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=False,\n",
    "    clf=LogisticRegression(),\n",
    "    tfidf=True,\n",
    "):\n",
    "\n",
    "    non_disaster_tweets = train_df[train_df['target'] == 0]['text'].tolist()\n",
    "    disaster_tweets = train_df[train_df['target'] == 1]['text'].tolist()\n",
    "\n",
    "    # Create vectorizer with limited vocabulary\n",
    "    vectorizer = create_vectorizer(\n",
    "        non_disaster_tweets,\n",
    "        disaster_tweets,\n",
    "        initial_vocab=initial_vocab,\n",
    "        remove_n_common_words=remove_n_common_words,\n",
    "        min_df=min_df,\n",
    "        max_features=max_features,\n",
    "        strip_accents=strip_accents,\n",
    "        lowercase=lowercase,\n",
    "        ngram_range=ngram_range,\n",
    "    )\n",
    "    \n",
    "    # Fit TF-IDF transformer\n",
    "    all_tweets = train_df['text']\n",
    "    tfidf_transformer = TfidfTransformer(\n",
    "        use_idf=use_idf,\n",
    "        norm=norm,\n",
    "        smooth_idf=smooth_idf,\n",
    "        sublinear_tf=sublinear_tf,\n",
    "    ).fit(vectorizer.transform(all_tweets))\n",
    "\n",
    "    # Create a pipeline to vectorize and apply TF-IDF\n",
    "    # Classifier is passed as an argument for comparison\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('tfidf', tfidf_transformer if tfidf else None),\n",
    "        (\"clf\", clf),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    X_train = all_tweets\n",
    "    y_train = train_df['target']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    preds_val = pipeline.predict(X_val)\n",
    "\n",
    "    if verbose:\n",
    "        # Display results on validation set\n",
    "        print(classification_report(y_val, preds_val))\n",
    "        ConfusionMatrixDisplay.from_estimator(pipeline, X_val, y_val, cmap='Blues', normalize='true')\n",
    "    \n",
    "    if return_artifacts:\n",
    "        return pipeline, X_train, X_val, y_train, y_val\n",
    "\n",
    "    # Return f1 macro average score\n",
    "    return f1_score(y_val, preds_val, average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a model\n",
    "TF-IDF will not necessarily improve performance. Let's evaluate its effects with a variety of SkLearn models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_parameters(parameters):\n",
    "    for params in product(*parameters.values()):\n",
    "        yield dict(zip(parameters.keys(), params))\n",
    "\n",
    "parameters = {\n",
    "    'clf': [\n",
    "        LogisticRegression(max_iter=2000, random_state=42),\n",
    "        RandomForestClassifier(max_depth=250, random_state=42), # Informed guess at max_depth\n",
    "        SGDClassifier(max_iter=2000, random_state=42),\n",
    "        SVC(max_iter=2000, random_state=42),\n",
    "        LinearSVC(max_iter=2000, random_state=42),\n",
    "        MultinomialNB(),\n",
    "    ],\n",
    "    'tfidf': [True, False],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for settings in grid_parameters(parameters):\n",
    "    f1_macro = evaluate_preprocessing(train_df, **settings, verbose=False)\n",
    "    results.append((settings, f1_macro))\n",
    "\n",
    "best_result = max(results, key=lambda x: x[1])\n",
    "print(\"Best result:\\n\", best_result)\n",
    "\n",
    "evaluate_preprocessing(train_df, **best_result[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 models:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'clf': SVC(max_iter=2000, random_state=42),\n",
       "   'tfidf': False,\n",
       "   'ngram_range': (1, 1)},\n",
       "  0.789233228475146),\n",
       " ({'clf': SVC(max_iter=2000, random_state=42),\n",
       "   'tfidf': True,\n",
       "   'ngram_range': (1, 1)},\n",
       "  0.7844887644132201),\n",
       " ({'clf': MultinomialNB(), 'tfidf': True, 'ngram_range': (1, 3)},\n",
       "  0.7812398369577)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Top 3 models:')\n",
    "sorted(results, key=lambda x: x[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of results\n",
    "\n",
    "We evaluated the effect of additional feature engineering:\n",
    "* TF-IDF weighting\n",
    "* Bigrams\n",
    "* Trigrams\n",
    "\n",
    "And several different ML models:\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* SGD\n",
    "* SVC\n",
    "* Linear SVC\n",
    "* Multinomial Naive Bayes\n",
    "\n",
    "The best results came from the model we already obtained in the previous notebook:\n",
    "\n",
    "**A simple bag of words model with Logistic Regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the model\n",
    "\n",
    "*(Copied from previous notebook with modifications to use the Pipeline)*\n",
    "\n",
    "An advantage of the bag of words + logistic regression model is its simplicity.\n",
    "\n",
    "We can simply look up the model coefficients to determine feature importance:\n",
    "* Which words contribute to a classification of \"disaster\" (1) or \"non-disaster\" (0)?\n",
    "\n",
    "There is no need to scale the coefficients here since all the features are from the BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following words have the highest positive coefficients (disaster):\n",
      "            Coefficients\n",
      "hiroshima       2.445416\n",
      "wildfire        2.359061\n",
      "earthquake      2.220706\n",
      "derailment      2.186881\n",
      "fires           2.132240\n",
      "tornado         1.992465\n",
      "riots           1.907593\n",
      "suicide         1.897605\n",
      "massacre        1.870264\n",
      "floods          1.869637\n",
      "\n",
      "The following words have the most negative coefficients (non-disaster):\n",
      "        Coefficients\n",
      "full       -1.564929\n",
      "better     -1.506215\n",
      "blight     -1.411568\n",
      "ebay       -1.404008\n",
      "bags       -1.243934\n",
      "cake       -1.237400\n",
      "upon       -1.234887\n",
      "show       -1.211611\n",
      "art        -1.197938\n",
      "likely     -1.184574\n"
     ]
    }
   ],
   "source": [
    "pipeline, X_train, X_val, y_train, y_val = evaluate_preprocessing(\n",
    "    train_df, **best_result[0], return_artifacts=True\n",
    ")\n",
    "\n",
    "model_coefficients = pd.DataFrame(\n",
    "   pipeline['clf'].coef_.T,\n",
    "   columns=['Coefficients'], index=pipeline['vect'].get_feature_names_out()\n",
    ")\n",
    "\n",
    "sorted_words = model_coefficients.sort_values('Coefficients', ascending=False)\n",
    "print('The following words have the highest positive coefficients (disaster):')\n",
    "print(sorted_words.head(10).to_string())\n",
    "\n",
    "print('\\nThe following words have the most negative coefficients (non-disaster):')\n",
    "print(sorted_words.tail(10)[::-1].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaining a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_explain(tweet, pipeline, settings):\n",
    "    \"\"\"Predict the class of a tweet and explain the prediction.\"\"\"\n",
    "    bow = pipeline['vect'].transform([tweet])\n",
    "    prediction = pipeline['clf'].predict(bow)[0]\n",
    "    word_importance = []\n",
    "    \n",
    "    # Get words from bow\n",
    "    words = pipeline['vect'].get_feature_names_out()\n",
    "\n",
    "    # Get model coefficients\n",
    "    coefficients = pipeline['clf'].coef_[0]\n",
    "\n",
    "    # Get coefficients for words in the tweet\n",
    "    for i, word in enumerate(words):\n",
    "        if bow[0, i] > 0:\n",
    "            word_importance.append((word, coefficients[i]))\n",
    "\n",
    "    word_importance = sorted(word_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f'Prediction: {\"disaster\" if prediction == 1 else \"non-disaster\"}\\n')\n",
    "    for word, coefficient in word_importance:\n",
    "        print(f'{word}: {coefficient:.2f}')\n",
    "    \n",
    "    return prediction, word_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So apparently there were bush fires near where I live over the weekend that I was totally oblivious to... \n",
      "\n",
      "Prediction: disaster\n",
      "\n",
      "fires: 2.13\n",
      "near: 0.95\n",
      "were: 0.81\n",
      "over: 0.71\n",
      "bush: 0.49\n",
      "was: 0.35\n",
      "apparently: 0.28\n",
      "that: 0.07\n",
      "totally: -0.01\n",
      "there: -0.01\n",
      "live: -0.02\n",
      "where: -0.37\n",
      "weekend: -0.41\n",
      "so: -0.49\n"
     ]
    }
   ],
   "source": [
    "tweet = train_df['text'].sample(1).values[0]\n",
    "print(tweet, '\\n')\n",
    "\n",
    "prediction, word_importance = predict_and_explain(tweet, pipeline, best_result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ec6_exam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32d7a0e0701bdeeaab07027fb8273d1e6dc5f66c0a91a8b21fdaab4a83de9cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
